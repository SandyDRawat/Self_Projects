{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJO/A59d5pTtsSi734FkZl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandyDRawat/Self_Projects/blob/main/Novel%20Automation%20Tool/With%20Translation/novel_downloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ebooklib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afI7at5TyX5n",
        "outputId": "355ce76c-5f6e-44db-d9fd-d6d5b82aef42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ebooklib\n",
            "  Downloading EbookLib-0.18.tar.gz (115 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/115.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from ebooklib) (4.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ebooklib) (1.16.0)\n",
            "Building wheels for collected packages: ebooklib\n",
            "  Building wheel for ebooklib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ebooklib: filename=EbookLib-0.18-py3-none-any.whl size=38778 sha256=261f0cef80fd887b3fbe75e2f0693f000ba48cfcfa0ffd0086ca5642ac54f359\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/38/cc/a3728bb72a315d9d8766fb71d362136372066fc25ad838f8fa\n",
            "Successfully built ebooklib\n",
            "Installing collected packages: ebooklib\n",
            "Successfully installed ebooklib-0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from ebooklib import epub\n",
        "from google_trans_new import google_translator"
      ],
      "metadata": {
        "id": "J7G0pyljn3_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_text(text):\n",
        "       translator = google_translator(timeout=5)\n",
        "       if type(text) is not str:\n",
        "           translate_text = ''\n",
        "           for substr in text:\n",
        "               translate_substr = translator.translate(substr,'hi')\n",
        "               translate_text += translate_substr\n",
        "       else:\n",
        "           translate_text = translator.translate(text,lang_tgt='hi', lang_src='en')\n",
        "       return translate_text\n"
      ],
      "metadata": {
        "id": "HTV3iEAFoUMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrapper(url):\n",
        "    req = requests.get(url)\n",
        "    if req.status_code == 200:\n",
        "        req.encoding = 'utf-8'\n",
        "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
        "        next_chapter_link = soup.find('a', id='next_chap')['href']\n",
        "        paragraphs = soup.find_all('p')\n",
        "        chapter_content = ''\n",
        "        for p in paragraphs:\n",
        "            #a = translate_text(p)\n",
        "            chapter_content += str(p)  # Convert to string to preserve HTML tags\n",
        "\n",
        "        return chapter_content, next_chapter_link\n",
        "    else:\n",
        "        print(\"Failed to retrieve content from the URL.\")\n",
        "        return None, None\n",
        "\n",
        "# Function to create an ePub file\n",
        "# Function to create an ePub file\n",
        "def create_epub(chapter_contents, novel_name, start_chapter, num_chapters):\n",
        "    end_chapter = start_chapter + num_chapters - 1\n",
        "    epub_name = f\"{novel_name}_{start_chapter}_to_{end_chapter}.epub\"\n",
        "    book = epub.EpubBook()\n",
        "    book.set_identifier(epub_name)\n",
        "    book.set_title(novel_name)\n",
        "    book.add_author(\"Author Name\")  # Replace with actual author name\n",
        "    for i, content in enumerate(chapter_contents, start=start_chapter):\n",
        "        chapter_number =chapter_numbers[i]  # Adjusting chapter number\n",
        "        chapter_content_with_number = f'<h1>Chapter {chapter_number}</h1>\\n{content}'\n",
        "        chapter = epub.EpubHtml(title=f'Chapter {chapter_number}', file_name=f'chapter_{chapter_number}.xhtml', lang='en')\n",
        "        chapter.content = chapter_content_with_number\n",
        "        book.add_item(chapter)\n",
        "        book.toc.append(chapter)\n",
        "    book.add_item(epub.EpubNcx())\n",
        "    book.add_item(epub.EpubNav())\n",
        "    style = 'body { font-family: Times, Times New Roman, serif; }'\n",
        "    nav_css = epub.EpubItem(uid=\"style_nav\", file_name=\"style/nav.css\", media_type=\"text/css\", content=style)\n",
        "    book.add_item(nav_css)\n",
        "    book.spine = ['nav'] + book.toc\n",
        "    epub.write_epub(epub_name, book)"
      ],
      "metadata": {
        "id": "Lz-KEu2PoCjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_chap(chap_contents):\n",
        "    content = ''\n",
        "    #print(type(chap_contents))\n",
        "    #print(chap_contents)\n",
        "    contents = chap_contents.split('</p>')\n",
        "    #print(chap_contents[3])\n",
        "    a = ''\n",
        "    for cont in contents:\n",
        "        #print(cont)\n",
        "        a += cont\n",
        "        if len(a) >4000:\n",
        "            content += translate_text(a)\n",
        "            a = ''\n",
        "    content += translate_text(a)\n",
        "    return content"
      ],
      "metadata": {
        "id": "VrQko7lVCih0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXTjF6aqpbzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed4926c6-f029-435d-f97a-50b2ec7f643c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "URL of The Starting Chapter: https://novelbin.englishnovel.net/novel-book/dimensional-descent/chapter-1\n",
            "Number of Chapters: 1\n"
          ]
        }
      ],
      "source": [
        "url = input(\"URL of The Starting Chapter: \")\n",
        "num_chapters_to_scrape = int(input(\"Number of Chapters: \"))\n",
        "\n",
        "# Extract novel name from URL\n",
        "novel_name = url.split('novel-book/')[1].split('/chapter')[0]\n",
        "\n",
        "# Initialize lists to store chapter content and chapter numbers\n",
        "chapter_contents = []\n",
        "chapter_numbers = []\n",
        "\n",
        "# Start scraping loop\n",
        "for i in range(num_chapters_to_scrape):\n",
        "    url0 = url\n",
        "    chapter_content, url = scrapper(url)\n",
        "    if chapter_content:\n",
        "       # print(chapter_content)\n",
        "       # print(translated_chap_content)\n",
        "        chapter_contents.append(translate_chap(chapter_content))\n",
        "\n",
        "        chapter_numbers.append(int(url0.split('/')[-1].split('-')[1]))\n",
        "    url = url.rsplit('-', 1)[0] + f'-{i + 2}'  # Correcting the URL for the next chapter\n",
        "   # print(i)\n",
        "\n",
        "# Get start chapter and end chapter\n",
        "start_chapter = min(chapter_numbers)\n",
        "end_chapter = start_chapter + num_chapters_to_scrape - 1\n",
        "\n",
        "#print(chapter_contents)\n",
        "# Export the content to ePub\n",
        "create_epub(chapter_contents, novel_name, start_chapter, num_chapters_to_scrape)\n"
      ]
    }
  ]
}